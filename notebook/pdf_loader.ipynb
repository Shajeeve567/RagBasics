{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "185eeb00",
   "metadata": {},
   "source": [
    "### Data Ingestion to Vector DB pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16b1c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55202e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 PDF files to process\n",
      "Processing: {pdf_file.name}\n",
      "✅ Loaded 1 pages\n",
      "Processing: {pdf_file.name}\n",
      "✅ Loaded 1 pages\n",
      "Processing: {pdf_file.name}\n",
      "✅ Loaded 2 pages\n",
      "Processing: {pdf_file.name}\n",
      "✅ Loaded 1 pages\n",
      "Processing: {pdf_file.name}\n",
      "✅ Loaded 1 pages\n",
      "\n",
      "Total documents loaded: 6\n"
     ]
    }
   ],
   "source": [
    "### Read all the pdfs inside the directory\n",
    "\n",
    "def process_all_pdfs(pdf_directory):\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(pdf_directory)\n",
    "\n",
    "    # Find all PDF files recursively\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "\n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        print(\"Processing: {pdf_file.name}\")\n",
    "        try:\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "\n",
    "            # Add source information to metadata\n",
    "            for doc in documents:\n",
    "                doc.metadata['source_file'] = pdf_file.name\n",
    "                doc.metadata['file_type'] = 'pdf'\n",
    "\n",
    "            all_documents.extend(documents)\n",
    "            print(f\"✅ Loaded {len(documents)} pages\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error {e}\")\n",
    "\n",
    "    print(f\"\\nTotal documents loaded: {len(all_documents)}\")\n",
    "    return all_documents\n",
    "\n",
    "# Process all PDFs in the data directory\n",
    "all_pdf_documents = process_all_pdfs(\"../data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f37de04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T11:26:34+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T11:26:34+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\data_engineering_for_ai_dummy.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'data_engineering_for_ai_dummy.pdf', 'file_type': 'pdf'}, page_content='Data Engineering for AI Systems\\nData Pipelines\\nAutomated flows that ingest, clean, and transform data.\\nETL vs ELT\\nETL transforms before loading; ELT transforms after loading.\\nData Quality\\nAccuracy, completeness, and consistency are critical for ML systems.\\nStorage Systems\\nData lakes, warehouses, and object storage support AI workloads.\\nImportance for RAG\\nReliable pipelines ensure high-quality documents for retrieval.'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T11:26:34+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T11:26:34+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\large_language_models_dummy.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'large_language_models_dummy.pdf', 'file_type': 'pdf'}, page_content='Large Language Models Overview\\nWhat are LLMs?\\nLarge Language Models are neural networks trained on massive text datasets.\\nTransformers\\nTransformers use attention mechanisms to model long-range dependencies.\\nPretraining vs Fine-tuning\\nPretraining learns general language patterns; fine-tuning adapts models to tasks.\\nLimitations\\nLLMs can hallucinate and lack real-time knowledge.\\nLLMs in RAG\\nRAG augments LLMs with external knowledge to improve accuracy.'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T04:39:02+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T04:39:02+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\machine_learning_for_rag_dummy.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1', 'source_file': 'machine_learning_for_rag_dummy.pdf', 'file_type': 'pdf'}, page_content='Machine Learning for RAG Systems\\nIntroduction\\nThis document is a dummy educational PDF designed to be used in a Retrieval-Augmented\\nGeneration (RAG) project. It contains foundational machine learning concepts commonly\\nreferenced by LLM-powered systems.\\nWhat is Machine Learning?\\nMachine Learning (ML) is a subset of artificial intelligence where systems learn patterns from data\\ninstead of being explicitly programmed. ML models improve performance as they see more data.\\nCore ML Paradigms\\nSupervised Learning: Learning from labeled data.\\nUnsupervised Learning: Discovering hidden patterns in unlabeled data.\\nReinforcement Learning: Learning through rewards and penalties.\\nEmbeddings\\nEmbeddings are dense vector representations of text, images, or other data. In RAG systems, text\\nembeddings allow semantic search over documents.\\nVector Databases\\nVector databases store embeddings and enable fast similarity search. Examples include FAISS,\\nPinecone, Weaviate, and Chroma.\\nSimilarity Search\\nSimilarity search retrieves documents whose embeddings are closest to a query embedding,\\ncommonly using cosine similarity or Euclidean distance.\\nRAG Pipeline Overview\\n1. Ingest documents\\n2. Chunk text\\n3. Generate embeddings\\n4. Store in vector database'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T04:39:02+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T04:39:02+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\machine_learning_for_rag_dummy.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2', 'source_file': 'machine_learning_for_rag_dummy.pdf', 'file_type': 'pdf'}, page_content='5. Retrieve relevant chunks\\n6. Generate answer using LLM\\nWhy RAG Matters\\nRAG systems reduce hallucinations, enable up-to-date knowledge access, and allow\\ndomain-specific grounding of large language models.\\nConclusion\\nThis PDF serves as a placeholder dataset for experimenting with document loading, chunking,\\nembedding generation, and retrieval in a RAG system.'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T11:26:34+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T11:26:34+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\nlp_fundamentals_dummy.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'nlp_fundamentals_dummy.pdf', 'file_type': 'pdf'}, page_content='Natural Language Processing Fundamentals\\nIntroduction to NLP\\nNatural Language Processing (NLP) enables machines to understand, interpret, and generate\\nhuman language.\\nTokenization\\nTokenization breaks text into words, subwords, or characters for model processing.\\nText Cleaning\\nIncludes lowercasing, stopword removal, stemming, and lemmatization.\\nLanguage Models\\nStatistical and neural models that predict the probability of word sequences.\\nNLP in RAG\\nNLP techniques help preprocess documents and interpret user queries.'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T11:26:34+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T11:26:34+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\vector_databases_dummy.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'vector_databases_dummy.pdf', 'file_type': 'pdf'}, page_content='Vector Databases and Similarity Search\\nWhat is a Vector Database?\\nA vector database stores embeddings for fast semantic search.\\nEmbeddings\\nNumerical representations of meaning produced by ML models.\\nSimilarity Metrics\\nCosine similarity, dot product, and Euclidean distance are commonly used.\\nIndexing Techniques\\nApproximate Nearest Neighbor (ANN) indexes improve retrieval speed.\\nRole in RAG\\nVector databases retrieve context documents for LLM generation.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pdf_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f115ef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Text splitting get into chunks\n",
    "\n",
    "def split_documents(documents, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"Split documents into smaller chunks for better RAG performs\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample chunk:\")\n",
    "        print(f\"Content: {split_docs[0].page_content[:200]}\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "\n",
    "    return split_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02863ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 6 documents into 7 chunks\n",
      "\n",
      "Example chunk:\n",
      "Content: Data Engineering for AI Systems\n",
      "Data Pipelines\n",
      "Automated flows that ingest, clean, and transform data.\n",
      "ETL vs ELT\n",
      "ETL transforms before loading; ELT transforms after loading.\n",
      "Data Quality\n",
      "Accuracy, co\n",
      "Metadata: {'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T11:26:34+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T11:26:34+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\data_engineering_for_ai_dummy.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'data_engineering_for_ai_dummy.pdf', 'file_type': 'pdf'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T11:26:34+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T11:26:34+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\data_engineering_for_ai_dummy.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'data_engineering_for_ai_dummy.pdf', 'file_type': 'pdf'}, page_content='Data Engineering for AI Systems\\nData Pipelines\\nAutomated flows that ingest, clean, and transform data.\\nETL vs ELT\\nETL transforms before loading; ELT transforms after loading.\\nData Quality\\nAccuracy, completeness, and consistency are critical for ML systems.\\nStorage Systems\\nData lakes, warehouses, and object storage support AI workloads.\\nImportance for RAG\\nReliable pipelines ensure high-quality documents for retrieval.'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T11:26:34+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T11:26:34+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\large_language_models_dummy.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'large_language_models_dummy.pdf', 'file_type': 'pdf'}, page_content='Large Language Models Overview\\nWhat are LLMs?\\nLarge Language Models are neural networks trained on massive text datasets.\\nTransformers\\nTransformers use attention mechanisms to model long-range dependencies.\\nPretraining vs Fine-tuning\\nPretraining learns general language patterns; fine-tuning adapts models to tasks.\\nLimitations\\nLLMs can hallucinate and lack real-time knowledge.\\nLLMs in RAG\\nRAG augments LLMs with external knowledge to improve accuracy.'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T04:39:02+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T04:39:02+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\machine_learning_for_rag_dummy.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1', 'source_file': 'machine_learning_for_rag_dummy.pdf', 'file_type': 'pdf'}, page_content='Machine Learning for RAG Systems\\nIntroduction\\nThis document is a dummy educational PDF designed to be used in a Retrieval-Augmented\\nGeneration (RAG) project. It contains foundational machine learning concepts commonly\\nreferenced by LLM-powered systems.\\nWhat is Machine Learning?\\nMachine Learning (ML) is a subset of artificial intelligence where systems learn patterns from data\\ninstead of being explicitly programmed. ML models improve performance as they see more data.\\nCore ML Paradigms\\nSupervised Learning: Learning from labeled data.\\nUnsupervised Learning: Discovering hidden patterns in unlabeled data.\\nReinforcement Learning: Learning through rewards and penalties.\\nEmbeddings\\nEmbeddings are dense vector representations of text, images, or other data. In RAG systems, text\\nembeddings allow semantic search over documents.\\nVector Databases\\nVector databases store embeddings and enable fast similarity search. Examples include FAISS,\\nPinecone, Weaviate, and Chroma.\\nSimilarity Search'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T04:39:02+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T04:39:02+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\machine_learning_for_rag_dummy.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1', 'source_file': 'machine_learning_for_rag_dummy.pdf', 'file_type': 'pdf'}, page_content='Vector Databases\\nVector databases store embeddings and enable fast similarity search. Examples include FAISS,\\nPinecone, Weaviate, and Chroma.\\nSimilarity Search\\nSimilarity search retrieves documents whose embeddings are closest to a query embedding,\\ncommonly using cosine similarity or Euclidean distance.\\nRAG Pipeline Overview\\n1. Ingest documents\\n2. Chunk text\\n3. Generate embeddings\\n4. Store in vector database'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T04:39:02+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T04:39:02+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\machine_learning_for_rag_dummy.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2', 'source_file': 'machine_learning_for_rag_dummy.pdf', 'file_type': 'pdf'}, page_content='5. Retrieve relevant chunks\\n6. Generate answer using LLM\\nWhy RAG Matters\\nRAG systems reduce hallucinations, enable up-to-date knowledge access, and allow\\ndomain-specific grounding of large language models.\\nConclusion\\nThis PDF serves as a placeholder dataset for experimenting with document loading, chunking,\\nembedding generation, and retrieval in a RAG system.'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T11:26:34+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T11:26:34+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\nlp_fundamentals_dummy.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'nlp_fundamentals_dummy.pdf', 'file_type': 'pdf'}, page_content='Natural Language Processing Fundamentals\\nIntroduction to NLP\\nNatural Language Processing (NLP) enables machines to understand, interpret, and generate\\nhuman language.\\nTokenization\\nTokenization breaks text into words, subwords, or characters for model processing.\\nText Cleaning\\nIncludes lowercasing, stopword removal, stemming, and lemmatization.\\nLanguage Models\\nStatistical and neural models that predict the probability of word sequences.\\nNLP in RAG\\nNLP techniques help preprocess documents and interpret user queries.'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T11:26:34+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T11:26:34+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\vector_databases_dummy.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'vector_databases_dummy.pdf', 'file_type': 'pdf'}, page_content='Vector Databases and Similarity Search\\nWhat is a Vector Database?\\nA vector database stores embeddings for fast semantic search.\\nEmbeddings\\nNumerical representations of meaning produced by ML models.\\nSimilarity Metrics\\nCosine similarity, dot product, and Euclidean distance are commonly used.\\nIndexing Techniques\\nApproximate Nearest Neighbor (ANN) indexes improve retrieval speed.\\nRole in RAG\\nVector databases retrieve context documents for LLM generation.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = split_documents(all_pdf_documents)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843b24cd",
   "metadata": {},
   "source": [
    "### Embedding and VectorStoreDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7011b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer # Embedding model\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c402831b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 887.81it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded sucessfully. Embedding dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x1f9a6af5430>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"Handles document embedding generation using SentenceTransformer\"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        self.model_name = model_name # initializing the model name\n",
    "        self.model = None  \n",
    "        self._load_model()  # loading the specialized model \n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the sentenceTransformer model\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)  # loading the model\n",
    "            print(f\"Model loaded sucessfully. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")   # getting the embedding dimension\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def generate_emeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "            Generate embeddings for a list of texts\n",
    "\n",
    "            Args:\n",
    "                texts: List of text strings to embed\n",
    "\n",
    "            returns:\n",
    "                numpy array of embeddings with shape (len(texts), embedding_dim)\n",
    "        \"\"\" \n",
    "        if not self.model:\n",
    "            raise ValueError(\"MOdel not loaded\")\n",
    "    \n",
    "        print(f\"Generating embedding for {len(texts)} texts...\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "    \n",
    "\n",
    "## Initializing the embedding manager\n",
    "\n",
    "embedding_manager = EmbeddingManager()\n",
    "embedding_manager\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7689a37c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c986b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RagFundamentals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
