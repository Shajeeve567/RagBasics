{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "185eeb00",
   "metadata": {},
   "source": [
    "### Data Ingestion to Vector DB pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16b1c62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\RagFundamentals\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55202e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 PDF files to process\n",
      "Processing: {pdf_file.name}\n",
      "✅ Loaded 1 pages\n",
      "Processing: {pdf_file.name}\n",
      "✅ Loaded 1 pages\n",
      "Processing: {pdf_file.name}\n",
      "✅ Loaded 2 pages\n",
      "Processing: {pdf_file.name}\n",
      "✅ Loaded 1 pages\n",
      "Processing: {pdf_file.name}\n",
      "✅ Loaded 1 pages\n",
      "\n",
      "Total documents loaded: 6\n"
     ]
    }
   ],
   "source": [
    "### Read all the pdfs inside the directory\n",
    "\n",
    "def process_all_pdfs(pdf_directory):\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(pdf_directory)\n",
    "\n",
    "    # Find all PDF files recursively\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "\n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        print(\"Processing: {pdf_file.name}\")\n",
    "        try:\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "\n",
    "            # Add source information to metadata\n",
    "            for doc in documents:\n",
    "                doc.metadata['source_file'] = pdf_file.name\n",
    "                doc.metadata['file_type'] = 'pdf'\n",
    "\n",
    "            all_documents.extend(documents)\n",
    "            print(f\"✅ Loaded {len(documents)} pages\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error {e}\")\n",
    "\n",
    "    print(f\"\\nTotal documents loaded: {len(all_documents)}\")\n",
    "    return all_documents\n",
    "\n",
    "# Process all PDFs in the data directory\n",
    "all_pdf_documents = process_all_pdfs(\"../data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f37de04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T11:26:34+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T11:26:34+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\data_engineering_for_ai_dummy.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'data_engineering_for_ai_dummy.pdf', 'file_type': 'pdf'}, page_content='Data Engineering for AI Systems\\nData Pipelines\\nAutomated flows that ingest, clean, and transform data.\\nETL vs ELT\\nETL transforms before loading; ELT transforms after loading.\\nData Quality\\nAccuracy, completeness, and consistency are critical for ML systems.\\nStorage Systems\\nData lakes, warehouses, and object storage support AI workloads.\\nImportance for RAG\\nReliable pipelines ensure high-quality documents for retrieval.'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T11:26:34+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T11:26:34+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\large_language_models_dummy.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'large_language_models_dummy.pdf', 'file_type': 'pdf'}, page_content='Large Language Models Overview\\nWhat are LLMs?\\nLarge Language Models are neural networks trained on massive text datasets.\\nTransformers\\nTransformers use attention mechanisms to model long-range dependencies.\\nPretraining vs Fine-tuning\\nPretraining learns general language patterns; fine-tuning adapts models to tasks.\\nLimitations\\nLLMs can hallucinate and lack real-time knowledge.\\nLLMs in RAG\\nRAG augments LLMs with external knowledge to improve accuracy.'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T04:39:02+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T04:39:02+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\machine_learning_for_rag_dummy.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1', 'source_file': 'machine_learning_for_rag_dummy.pdf', 'file_type': 'pdf'}, page_content='Machine Learning for RAG Systems\\nIntroduction\\nThis document is a dummy educational PDF designed to be used in a Retrieval-Augmented\\nGeneration (RAG) project. It contains foundational machine learning concepts commonly\\nreferenced by LLM-powered systems.\\nWhat is Machine Learning?\\nMachine Learning (ML) is a subset of artificial intelligence where systems learn patterns from data\\ninstead of being explicitly programmed. ML models improve performance as they see more data.\\nCore ML Paradigms\\nSupervised Learning: Learning from labeled data.\\nUnsupervised Learning: Discovering hidden patterns in unlabeled data.\\nReinforcement Learning: Learning through rewards and penalties.\\nEmbeddings\\nEmbeddings are dense vector representations of text, images, or other data. In RAG systems, text\\nembeddings allow semantic search over documents.\\nVector Databases\\nVector databases store embeddings and enable fast similarity search. Examples include FAISS,\\nPinecone, Weaviate, and Chroma.\\nSimilarity Search\\nSimilarity search retrieves documents whose embeddings are closest to a query embedding,\\ncommonly using cosine similarity or Euclidean distance.\\nRAG Pipeline Overview\\n1. Ingest documents\\n2. Chunk text\\n3. Generate embeddings\\n4. Store in vector database'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T04:39:02+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T04:39:02+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\machine_learning_for_rag_dummy.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2', 'source_file': 'machine_learning_for_rag_dummy.pdf', 'file_type': 'pdf'}, page_content='5. Retrieve relevant chunks\\n6. Generate answer using LLM\\nWhy RAG Matters\\nRAG systems reduce hallucinations, enable up-to-date knowledge access, and allow\\ndomain-specific grounding of large language models.\\nConclusion\\nThis PDF serves as a placeholder dataset for experimenting with document loading, chunking,\\nembedding generation, and retrieval in a RAG system.'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T11:26:34+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T11:26:34+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\nlp_fundamentals_dummy.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'nlp_fundamentals_dummy.pdf', 'file_type': 'pdf'}, page_content='Natural Language Processing Fundamentals\\nIntroduction to NLP\\nNatural Language Processing (NLP) enables machines to understand, interpret, and generate\\nhuman language.\\nTokenization\\nTokenization breaks text into words, subwords, or characters for model processing.\\nText Cleaning\\nIncludes lowercasing, stopword removal, stemming, and lemmatization.\\nLanguage Models\\nStatistical and neural models that predict the probability of word sequences.\\nNLP in RAG\\nNLP techniques help preprocess documents and interpret user queries.'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T11:26:34+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T11:26:34+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\vector_databases_dummy.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'vector_databases_dummy.pdf', 'file_type': 'pdf'}, page_content='Vector Databases and Similarity Search\\nWhat is a Vector Database?\\nA vector database stores embeddings for fast semantic search.\\nEmbeddings\\nNumerical representations of meaning produced by ML models.\\nSimilarity Metrics\\nCosine similarity, dot product, and Euclidean distance are commonly used.\\nIndexing Techniques\\nApproximate Nearest Neighbor (ANN) indexes improve retrieval speed.\\nRole in RAG\\nVector databases retrieve context documents for LLM generation.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pdf_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f115ef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Text splitting get into chunks\n",
    "\n",
    "def split_documents(documents, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"Split documents into smaller chunks for better RAG performs\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample chunk:\")\n",
    "        print(f\"Content: {split_docs[0].page_content[:200]}\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "\n",
    "    return split_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02863ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 6 documents into 7 chunks\n",
      "\n",
      "Example chunk:\n",
      "Content: Data Engineering for AI Systems\n",
      "Data Pipelines\n",
      "Automated flows that ingest, clean, and transform data.\n",
      "ETL vs ELT\n",
      "ETL transforms before loading; ELT transforms after loading.\n",
      "Data Quality\n",
      "Accuracy, co\n",
      "Metadata: {'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T11:26:34+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T11:26:34+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\data_engineering_for_ai_dummy.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'data_engineering_for_ai_dummy.pdf', 'file_type': 'pdf'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T11:26:34+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T11:26:34+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\data_engineering_for_ai_dummy.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'data_engineering_for_ai_dummy.pdf', 'file_type': 'pdf'}, page_content='Data Engineering for AI Systems\\nData Pipelines\\nAutomated flows that ingest, clean, and transform data.\\nETL vs ELT\\nETL transforms before loading; ELT transforms after loading.\\nData Quality\\nAccuracy, completeness, and consistency are critical for ML systems.\\nStorage Systems\\nData lakes, warehouses, and object storage support AI workloads.\\nImportance for RAG\\nReliable pipelines ensure high-quality documents for retrieval.'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T11:26:34+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T11:26:34+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\large_language_models_dummy.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'large_language_models_dummy.pdf', 'file_type': 'pdf'}, page_content='Large Language Models Overview\\nWhat are LLMs?\\nLarge Language Models are neural networks trained on massive text datasets.\\nTransformers\\nTransformers use attention mechanisms to model long-range dependencies.\\nPretraining vs Fine-tuning\\nPretraining learns general language patterns; fine-tuning adapts models to tasks.\\nLimitations\\nLLMs can hallucinate and lack real-time knowledge.\\nLLMs in RAG\\nRAG augments LLMs with external knowledge to improve accuracy.'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T04:39:02+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T04:39:02+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\machine_learning_for_rag_dummy.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1', 'source_file': 'machine_learning_for_rag_dummy.pdf', 'file_type': 'pdf'}, page_content='Machine Learning for RAG Systems\\nIntroduction\\nThis document is a dummy educational PDF designed to be used in a Retrieval-Augmented\\nGeneration (RAG) project. It contains foundational machine learning concepts commonly\\nreferenced by LLM-powered systems.\\nWhat is Machine Learning?\\nMachine Learning (ML) is a subset of artificial intelligence where systems learn patterns from data\\ninstead of being explicitly programmed. ML models improve performance as they see more data.\\nCore ML Paradigms\\nSupervised Learning: Learning from labeled data.\\nUnsupervised Learning: Discovering hidden patterns in unlabeled data.\\nReinforcement Learning: Learning through rewards and penalties.\\nEmbeddings\\nEmbeddings are dense vector representations of text, images, or other data. In RAG systems, text\\nembeddings allow semantic search over documents.\\nVector Databases\\nVector databases store embeddings and enable fast similarity search. Examples include FAISS,\\nPinecone, Weaviate, and Chroma.\\nSimilarity Search'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T04:39:02+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T04:39:02+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\machine_learning_for_rag_dummy.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1', 'source_file': 'machine_learning_for_rag_dummy.pdf', 'file_type': 'pdf'}, page_content='Vector Databases\\nVector databases store embeddings and enable fast similarity search. Examples include FAISS,\\nPinecone, Weaviate, and Chroma.\\nSimilarity Search\\nSimilarity search retrieves documents whose embeddings are closest to a query embedding,\\ncommonly using cosine similarity or Euclidean distance.\\nRAG Pipeline Overview\\n1. Ingest documents\\n2. Chunk text\\n3. Generate embeddings\\n4. Store in vector database'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T04:39:02+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T04:39:02+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\machine_learning_for_rag_dummy.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2', 'source_file': 'machine_learning_for_rag_dummy.pdf', 'file_type': 'pdf'}, page_content='5. Retrieve relevant chunks\\n6. Generate answer using LLM\\nWhy RAG Matters\\nRAG systems reduce hallucinations, enable up-to-date knowledge access, and allow\\ndomain-specific grounding of large language models.\\nConclusion\\nThis PDF serves as a placeholder dataset for experimenting with document loading, chunking,\\nembedding generation, and retrieval in a RAG system.'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T11:26:34+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T11:26:34+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\nlp_fundamentals_dummy.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'nlp_fundamentals_dummy.pdf', 'file_type': 'pdf'}, page_content='Natural Language Processing Fundamentals\\nIntroduction to NLP\\nNatural Language Processing (NLP) enables machines to understand, interpret, and generate\\nhuman language.\\nTokenization\\nTokenization breaks text into words, subwords, or characters for model processing.\\nText Cleaning\\nIncludes lowercasing, stopword removal, stemming, and lemmatization.\\nLanguage Models\\nStatistical and neural models that predict the probability of word sequences.\\nNLP in RAG\\nNLP techniques help preprocess documents and interpret user queries.'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2026-02-07T11:26:34+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2026-02-07T11:26:34+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\vector_databases_dummy.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'vector_databases_dummy.pdf', 'file_type': 'pdf'}, page_content='Vector Databases and Similarity Search\\nWhat is a Vector Database?\\nA vector database stores embeddings for fast semantic search.\\nEmbeddings\\nNumerical representations of meaning produced by ML models.\\nSimilarity Metrics\\nCosine similarity, dot product, and Euclidean distance are commonly used.\\nIndexing Techniques\\nApproximate Nearest Neighbor (ANN) indexes improve retrieval speed.\\nRole in RAG\\nVector databases retrieve context documents for LLM generation.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = split_documents(all_pdf_documents)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843b24cd",
   "metadata": {},
   "source": [
    "### Embedding and VectorStoreDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e7011b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4eab8f79",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'package' from partially initialized module 'torch' (most likely due to a circular import) (c:\\Users\\User\\Desktop\\RagFundamentals\\.venv\\Lib\\site-packages\\torch\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpython:\u001b[39m\u001b[33m\"\u001b[39m, sys.executable)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mtorch:\u001b[39m\u001b[33m\"\u001b[39m, torch.__version__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\RagFundamentals\\.venv\\Lib\\site-packages\\torch\\__init__.py:2204\u001b[39m\n\u001b[32m   2197\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_compile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _disable_dynamo  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m   2199\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   2200\u001b[39m \u001b[38;5;66;03m# Import interface functions defined in Python\u001b[39;00m\n\u001b[32m   2201\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   2202\u001b[39m \n\u001b[32m   2203\u001b[39m \u001b[38;5;66;03m# needs to be after the above ATen bindings so we can overwrite from Python side\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2204\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _VF \u001b[38;5;28;01mas\u001b[39;00m _VF, functional \u001b[38;5;28;01mas\u001b[39;00m functional  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m   2205\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# usort: skip # noqa: F403\u001b[39;00m\n\u001b[32m   2207\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   2208\u001b[39m \u001b[38;5;66;03m# Remove unnecessary members\u001b[39;00m\n\u001b[32m   2209\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\RagFundamentals\\.venv\\Lib\\site-packages\\torch\\functional.py:8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, TYPE_CHECKING\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _VF, Tensor\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _add_docstr\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\RagFundamentals\\.venv\\Lib\\site-packages\\torch\\nn\\__init__.py:8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# mypy: allow-untyped-defs\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparameter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m      3\u001b[39m     Buffer \u001b[38;5;28;01mas\u001b[39;00m Buffer,\n\u001b[32m      4\u001b[39m     Parameter \u001b[38;5;28;01mas\u001b[39;00m Parameter,\n\u001b[32m      5\u001b[39m     UninitializedBuffer \u001b[38;5;28;01mas\u001b[39;00m UninitializedBuffer,\n\u001b[32m      6\u001b[39m     UninitializedParameter \u001b[38;5;28;01mas\u001b[39;00m UninitializedParameter,\n\u001b[32m      7\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# usort: skip # noqa: F403\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     attention \u001b[38;5;28;01mas\u001b[39;00m attention,\n\u001b[32m     11\u001b[39m     functional \u001b[38;5;28;01mas\u001b[39;00m functional,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     utils \u001b[38;5;28;01mas\u001b[39;00m utils,\n\u001b[32m     17\u001b[39m )\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparallel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataParallel \u001b[38;5;28;01mas\u001b[39;00m DataParallel\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\RagFundamentals\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodule\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Module  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bilinear, Identity, LazyLinear, Linear  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      4\u001b[39m     CELU,\n\u001b[32m      5\u001b[39m     ELU,\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m     Threshold,\n\u001b[32m     33\u001b[39m )\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01madaptive\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AdaptiveLogSoftmaxWithLoss\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\RagFundamentals\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F, init\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparameter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Parameter, UninitializedParameter\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlazy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LazyModuleMixin\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\RagFundamentals\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:17\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _VF, sym_int \u001b[38;5;28;01mas\u001b[39;00m _sym_int, Tensor\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     _add_docstr,\n\u001b[32m     13\u001b[39m     _infer_size,\n\u001b[32m     14\u001b[39m     _ScalingType \u001b[38;5;28;01mas\u001b[39;00m ScalingType,\n\u001b[32m     15\u001b[39m     _SwizzleType \u001b[38;5;28;01mas\u001b[39;00m SwizzleType,\n\u001b[32m     16\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_jit_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     18\u001b[39m     _overload,\n\u001b[32m     19\u001b[39m     boolean_dispatch,\n\u001b[32m     20\u001b[39m     BroadcastingList1,\n\u001b[32m     21\u001b[39m     BroadcastingList2,\n\u001b[32m     22\u001b[39m     BroadcastingList3,\n\u001b[32m     23\u001b[39m )\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_torch_docs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m reproducibility_notes, sparse_support_notes, tf32_notes\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _reduction \u001b[38;5;28;01mas\u001b[39;00m _Reduction, grad  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\RagFundamentals\\.venv\\Lib\\site-packages\\torch\\_jit_internal.py:45\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# This is needed. `torch._jit_internal` is imported before `torch.distributed.__init__`.\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Explicitly ask to import `torch.distributed.__init__` first.\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Otherwise, \"AttributeError: module 'torch' has no attribute 'distributed'\" is raised.\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrpc\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpackage\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_mangling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpackage_mangling\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_awaits\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _Await\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _Await \u001b[38;5;28;01mas\u001b[39;00m CAwait, Future \u001b[38;5;28;01mas\u001b[39;00m CFuture\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'package' from partially initialized module 'torch' (most likely due to a circular import) (c:\\Users\\User\\Desktop\\RagFundamentals\\.venv\\Lib\\site-packages\\torch\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import sys, torch\n",
    "print(\"python:\", sys.executable)\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torch file:\", torch.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d74e57b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer# Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c402831b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 458.83it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded sucessfully. Embedding dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x14608be3830>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"Handles document embedding generation using SentenceTransformer\"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        self.model_name = model_name # initializing the model name\n",
    "        self.model = None  \n",
    "        self._load_model()  # loading the specialized model \n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the sentenceTransformer model\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)  # loading the model\n",
    "            print(f\"Model loaded sucessfully. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")   # getting the embedding dimension\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def generate_emeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "            Generate embeddings for a list of texts\n",
    "\n",
    "            Args:\n",
    "                texts: List of text strings to embed\n",
    "\n",
    "            returns:\n",
    "                numpy array of embeddings with shape (len(texts), embedding_dim)\n",
    "        \"\"\" \n",
    "        if not self.model:\n",
    "            raise ValueError(\"MOdel not loaded\")\n",
    "    \n",
    "        print(f\"Generating embedding for {len(texts)} texts...\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "    \n",
    "\n",
    "## Initializing the embedding manager\n",
    "\n",
    "embedding_manager = EmbeddingManager()\n",
    "embedding_manager\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ec3d3b",
   "metadata": {},
   "source": [
    "### Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7689a37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStore:\n",
    "    \"\"\"Manages document embeddings in a ChromaDB vector store\"\"\"\n",
    "\n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str = \"../data/vector_store\"):\n",
    "        \"\"\"\n",
    "        Initialize the vector Store\n",
    "\n",
    "        Args:\n",
    "            collection_name: Name of the ChromaDB collection\n",
    "            persist_directory: Directory to persist the vector store\n",
    "        \"\"\"\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize ChromaDB client and collection\"\"\"\n",
    "        try:\n",
    "            # Create persistent ChromaDB client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory) # creating a client that has the reference to the vectordb\n",
    "\n",
    "            # Get or Create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description\": \"PDF document embeddings for RAG\"}\n",
    "            )\n",
    "            print(f\"Vector store initialized. Collection: {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"{e}\")\n",
    "\n",
    "\n",
    "    def add_document(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        \"\"\"\n",
    "        Add documents and their embeddings to the vector store\n",
    "\n",
    "        Args:\n",
    "            documents: List of Langchain documents\n",
    "            embeddings: Corresponding embeddings for the documents\n",
    "        \"\"\"\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "\n",
    "        # Prepare data for ChromaDB\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737ccc11",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c986b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragfundamentals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
